# DGEMM Sequencial e Paralelo com OpenMP

Este projeto implementa e compara a multiplica√ß√£o de matrizes (`DGEMM`) de forma **sequencial** e **paralela** utilizando **OpenMP**.  
S√£o aplicadas t√©cnicas de otimiza√ß√£o como **tiling (blocking)**, **transposi√ß√£o da matriz B** e **register blocking** para melhor aproveitamento de cache.

---


**Universidade:** Universidade Estadual de Santa Cruz  
**Curso:** Engenharia de Computa√ß√£o / Processamento Paralelo  
**Disciplina:** DEC107 - Processamento Paralelo  
**Professor:** Dr. Esbel Tom√°s Valero Orellana  
**Alunos:** Brenno S. Flor√™ncio e Mateus Soares  
**Data:** 28/09/2025 

---

## üîß Compila√ß√£o

Compile o c√≥digo no Linux com o comando:

```bash
gcc -o dgemmSeqPar -Wall -O3 -fopenmp -march=native -mfma dgemmSeqParGPT.c -lm
```

Explica√ß√£o das flags:  
- `-Wall` ‚Üí mostra todos os avisos do compilador.  
- `-O3` ‚Üí n√≠vel alto de otimiza√ß√£o.  
- `-fopenmp` ‚Üí habilita OpenMP.  
- `-march=native` ‚Üí usa instru√ß√µes espec√≠ficas da sua CPU.  
- `-mfma` ‚Üí habilita instru√ß√µes FMA (fused multiply-add) se dispon√≠veis.  
- `-lm` ‚Üí linka a biblioteca matem√°tica.

---

## ‚ñ∂Ô∏è Execu√ß√£o

Rode o programa passando o tamanho da matriz quadrada `N`:

```bash
./dgemmSeqPar
Matrix size: 1024
```

---

## üìä Sa√≠da esperada

O programa gera como sa√≠da:

1. **Tempo de execu√ß√£o** da vers√£o sequencial e das vers√µes paralelas com 2, 4, 8 e 12 threads.  
2. **Speedup** ‚Üí quanto a vers√£o paralela foi mais r√°pida em rela√ß√£o √† sequencial.  
3. **Efici√™ncia** ‚Üí qu√£o bem os threads foram aproveitados (`speedup / n√∫mero de threads`).  
4. **Diferen√ßa num√©rica** entre os resultados sequencial e paralelo (verifica√ß√£o de corretude).

Exemplo de sa√≠da:

```
dgemmSeq time: 0.337004 seconds
dgemmPar with 2 threads time: 0.188320 seconds
dgemmPar with 4 threads time: 0.126693 seconds
dgemmPar with 8 threads time: 0.122472 seconds
dgemmPar with 12 threads time: 0.119871 seconds

Speedup with 2 threads: 1.78
Speedup with 4 threads: 2.66
Speedup with 8 threads: 2.75
Speedup with 12 threads: 2.81

Efficiency with 2 threads: 0.89
Efficiency with 4 threads: 0.66
Efficiency with 8 threads: 0.34
Efficiency with 12 threads: 0.23

Calculating differences between sequential and parallel results...
Difference with 2 threads: 0.000000e+00
Difference with 4 threads: 0.000000e+00
Difference with 8 threads: 0.000000e+00
Difference with 12 threads: 0.000000e+00
```

---

## üìö T√©cnicas usadas

- **Transposi√ß√£o de B** ‚Üí melhora a localidade de acesso.  
- **Blocking (tiling)** ‚Üí divide as matrizes em blocos de 64x64 para melhor uso do cache.  
- **Register blocking** ‚Üí acumula parciais em registradores para reduzir acessos √† mem√≥ria.  
- **OpenMP** ‚Üí paraleliza√ß√£o do loop externo com `#pragma omp parallel for collapse(2)`.

---
